<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>李巍爬虫 | Hanson&#39;s Blog</title>
<meta name="keywords" content="爬虫实战,爬虫,爬虫项目,爬虫学习">
<meta name="description" content="B站李巍爬虫学习总结">
<meta name="author" content="
作者:&nbsp;hanson">
<link rel="canonical" href="https://hanson00.github.io/posts/technology/python/%E6%9D%8E%E5%B7%8D%E7%88%AC%E8%99%AB/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.90e638a5d4448bfb1fe445aebfe0f00ba8831874539fc42477608012af462729.css" integrity="sha256-kOY4pdREi/sf5EWuv&#43;DwC6iDGHRTn8Qkd2CAEq9GJyk=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://hanson00.github.io/posts/imgs/66.jpg">
<link rel="icon" type="image/png" sizes="16x16" href="https://hanson00.github.io/posts/imgs/favicon16x16.ico">
<link rel="icon" type="image/png" sizes="32x32" href="https://hanson00.github.io/posts/imgs/favicon32x32.ico">
<link rel="apple-touch-icon" href="https://hanson00.github.io/posts/imgs/66.jpg">
<link rel="mask-icon" href="https://hanson00.github.io/posts/imgs/66.jpg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="李巍爬虫" />
<meta property="og:description" content="B站李巍爬虫学习总结" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://hanson00.github.io/posts/technology/python/%E6%9D%8E%E5%B7%8D%E7%88%AC%E8%99%AB/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-06-26T17:13:41&#43;08:00" />
<meta property="article:modified_time" content="2022-06-26T17:13:41&#43;08:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="李巍爬虫"/>
<meta name="twitter:description" content="B站李巍爬虫学习总结"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://hanson00.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "💻技术类文章",
      "item": "https://hanson00.github.io/posts/technology/"
    }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "Python文章",
      "item": "https://hanson00.github.io/posts/technology/python/"
    }, 
    {
      "@type": "ListItem",
      "position":  4 ,
      "name": "李巍爬虫",
      "item": "https://hanson00.github.io/posts/technology/python/%E6%9D%8E%E5%B7%8D%E7%88%AC%E8%99%AB/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "李巍爬虫",
  "name": "李巍爬虫",
  "description": "B站李巍爬虫学习总结",
  "keywords": [
    "爬虫实战,爬虫,爬虫项目,爬虫学习"
  ],
  "articleBody": "爬虫基础 爬虫基本流程\n1.初始化URL，并将URL放入待爬取的队列 2.将URl通过DNS解析IP，将对应IP的站点下载到HTML页面，并保存到本地，爬取完的URL放到已爬取队列 3.分析网页内容，找出网页里面关心的URL链接和内容，继续执行第二步\n 获取网页 提取信息 保存数据 自动化程序  爬虫如果需要模拟则把该网站下面的所有请求信息封装(例如UA)然后发送\nHTTP请求方法 请求，是由客户端向服务器发出一般分为4部分内容：请求方法（request method）、请求的网址（request url）、请求头（request Headers）、请求体（request Body）\n   1 GET 请求指定的页面信息，并返回实体主体。     2 HEAD 类似于 GET 请求，只不过返回的响应中没有具体的内容，用于获取报头   3 POST 向指定资源提交数据进行处理请求（例如提交表单或者上传文件）。数据被包含在请求体中。POST 请求可能会导致新的资源的建立和/或已有资源的修改。   4 PUT 从客户端向服务器传送的数据取代指定的文档的内容。   5 DELETE 请求服务器删除指定的页面。   6 CONNECT HTTP/1.1 协议中预留给能够将连接改为管道方式的代理服务器。   7 OPTIONS 允许客户端查看服务器的性能。   8 TRACE 回显服务器收到的请求，主要用于测试或诊断。   9 PATCH 是对 PUT 方法的补充，用来对已知资源进行局部更新 。    请求头 请求头，用来说明服务器要使用的附加信息，比较重要的信息有，cookie、Refer、User-Agent\n响应 响应，由服务器端返回给客户端，分为响应状态码（Response Status Code）、响应头（Response headers）、响应体（Response Body）\n响应头 包含了服务器对请求的应答信息\n 小知识  Host:域名。表示请求的服务器网址   爬虫分类 通用爬虫 聚焦爬虫  爬虫学习 urllib.request.urlopen(url, data=None, [timeout, ]*, cafile=None, capath=None, cadefault=False, context=None)打开一个网页并把获取该URL的网页对象 data 必须是一个对象，用于给出要发送到服务器的附加数据，若不需要发送数据则为 None，data支持的对象类型包括字节串、类文件对象和可遍历的类字节串对象\nurllib.request.urlopen()  一个简单的get请求爬取\n 1 2 3 4 5 6 7 8 9 10 11  import urllib.request import urllib.parse #解析器 import urllib.error #Get请求 response = urllib.request.urlopen(\"http://www.baidu.com\") print(response.read().decode(\"UTF-8\"))\t# response是 url = \"http://httpbin.org/get\" response2 = urllib.request.urlopen(url=url) print(response2.read().decode(\"UTF-8\"))    一个简单的post请求(post请求需要提交个表单信息)，需要提供一个封装的数据\n 1 2 3 4 5  #post请求 需要封装数据 http://httpbin.org/post url = \"http://httpbin.org/post\" data = bytes(urllib.parse.urlencode({\"hello\":\"world\"}), encoding = \"utf-8\")\t#把数据变成二进制格式 response = urllib.request.urlopen(url=url, data=data) print(response.read().decode(\"utf-8\"))   urllib.request.Request() urllib.request.Request(url, data=None, headers={}, origin_req_host=None, unverifiable=False, method=None) 上面的urlopen过于简单直接把赋值的url直接打开，包含不了太多伪装信息，所以使用==urllib.request.Request()==\nheaders：告诉要访问的服务器，我们是什么类型的机器（浏览器），本质上是告诉浏览器我们可以接受什么水平的文件内容\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  import urllib.request import urllib.parse #解析器 import urllib.error # http://httpbin.org/post https://www.douban.com url = \"http://httpbin.org/post\" headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36\" \" (KHTML, like Gecko) Chrome/97.0.4692.99 Safari/537.36\"} data = bytes(urllib.parse.urlencode({\"name\":\"hanson\"}),encoding = \"UTF-8\") #封装了一个请求对象 req = urllib.request.Request(url=url, data=data, headers=headers) response = urllib.request.urlopen(req)\t#响应对象 print(response.read().decode(\"UTF-8\"))   简单的爬取网页 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47  import urllib.request import urllib.error def main(): #基础的URL # 1.爬取网页 baseurl = \"https://movie.douban.com/top250?start=\" savepath = r\"D:\\project\\python pycharm\\datasave\\douban_data.xlsx\" # datalist = getData(baseurl) getData(baseurl) #2.解析数据 #3.保存数据 # saveData(savepath) def getData(baseurl): datalist = [] for i in range(0, 10): url = baseurl + str(i*25) html = askurl(url) return datalist # 3.保存数据,在本列子中暂时不用 def saveData(savepath): pass # 得到一个指定的URL的网页内容 def askurl(url): head = { \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36\" \" (KHTML, like Gecko) Chrome/97.0.4692.99 Safari/537.36\" } html = \"\" try: req = urllib.request.Request(url=url, headers=head) response = urllib.request.urlopen(req) html= response.read().decode(\"UTF-8\") print(html) except Exception as e: print(e) return html if __name__ == \"__main__\": main()   BeautifulSoup库的基本使用(爬虫的解析) BeautifulSoup4将HTML文档转换成树形结构，每个节点都是Python对象，归类成四种：\n Tag\t可以获取标签及其标签内容 NavigableString BeautifulSoup comment  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  import bs4 with open(\"../baidu.html\", \"rb\") as file: htmlread = file.read() bs = bs4.BeautifulSoup(htmlread, \"html.parser\") # Tag 获取标签及内容 print(bs.title) #output: 百度一下，你就知道  print(bs.a) #output:  # 获取标签里面的内容 print(bs.title.string) #output: 百度一下，你就知道 print(bs.a.string) #output: 新闻 # NavigableString 获取标签里的所有属性，并返回一个字典 print(bs.a.attrs) #attrs是attribute属性的缩写 # print(bs) 打印整个html文件 # 文件的遍历 contents print(\"-----文档的遍历-----\") print(bs.head.contents) #返回一个列表   BeautifulSoup2.0文档搜索 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45  import re import bs4 with open(\"../baidu.html\", \"rb\") as file: htmlread = file.read() bs = bs4.BeautifulSoup(htmlread, \"html.parser\") #文档搜索 # 1. find_all()方法:字符串过滤会查找与字符串完全匹配的内容 list = bs.find_all(\"a\") # list = bs.find_all(\"a\", limit = 3) limit限制多少 print(list) #正则表达式搜索 print(\"---正则表达式搜索---\") re_list = bs.find_all(re.compile(\"a\")) print(re_list) print(len(re_list)) #传入一个函数作为参数进行搜索,按照函数进行搜索 print(\"---函数搜索---\") def name_is_exists(tag): return tag.has_attr(\"name\") funcres = bs.find_all(name_is_exists) print(funcres) #kwargs关键字搜索 print(\"----kwargs关键字搜索----\") kwlist = bs.find_all(id = \"head\") kwlist2 = bs.find_all(href = \"https://www.hao123.com\") kwlist3 = bs.find_all(class_ = True) #这里class加下划线是因为class是Python的关键字 print(kwlist3) #text文本参数,查找标签里的字符串 print(\"----text文本参数-----\") ts_list = bs.find_all(text=\"hao123\") ts_list2 = bs.find_all(text=[\"hao123\", \"地图\"]) print(ts_list2) #css选择器,和css选择器的语法一样 print(\"------css选择器-------\") css_list = bs.select(\"title\") css_list2 = bs.select(\".mnav\") css_list3 = bs.select(\"#u1\") css_list4 = bs.select(\"a[class = 'bri']\") print(css_list3)   liwei爬虫学习的最终 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108  # coding:utf-8 # @Time : 2022/5/7 9:57 # @Author : 软件1194温铭军 # @file : ts.py # $software : PyCharm import bs4 import re import xlwt import urllib.request import urllib.error def main(): baseurl = \"https://movie.douban.com/top250?start=\" #待爬取的URL savepath = r\"D:\\project\\python pycharm\\datasave\\douban_data.xls\" #保存位置 datalist = getData(baseurl) #爬取到的数据列表 # getData(baseurl) # print(datalist) #3.保存数据 saveData(datalist,savepath) # 提取影片的提取规则 recom_link = re.compile(r'') recom_img = re.compile(r'', re.S) #re.S让换行符也包含在内 recom_title = re.compile(r'(.*?)') recom_rating = re.compile(r'(.*?)') recom_judge = re.compile(r'(\\d*)人评价') recom_inq = re.compile(r'(.*?)') recom_db = re.compile(r'(.*?)\n',re.S) def getData(baseurl): datalist = [] #生成要爬取的网址 for i in range(0, 10): url = baseurl + str(i*25) html = askurl(url) #进行数据解析 soup = bs4.BeautifulSoup(html, \"html.parser\") for item in soup.find_all(\"div\", class_ = \"item\"):\t#在中查找是div并且class=\"item\"的内容 # print(item) data = [] #保存每一部电影的信息 item = str(item) link = re.findall(recom_link, item)[0] data.append(link) #添加链接 img = re.findall(recom_img, item)[0] data.append(img) title = re.findall(recom_title, item) if (len(title) ==2): ctitle = title[0] data.append(ctitle) otitle = title[1].replace(\"/\",\"\") #去掉无关符号 data.append(otitle) else: data.append(title[0]) data.append(\" \") #留空 rating = re.findall(recom_rating, item)[0] data.append(rating) judge = re.findall(recom_judge, item)[0] data.append(judge) inq = re.findall(recom_inq, item) if len(inq) !=0: inq = inq[0].replace(\"。\", \" \") data.append(inq) else: data.append(\" \") db = re.findall(recom_db, item)[0] db = re.sub('(\\s+)?', \"\", db) db = re.sub('/', \" \", db) data.append(db.strip()) datalist.append(data) # print(datalist) return datalist # 3.保存数据 def saveData(datalist,savepath): wb = xlwt.Workbook(encoding=\"UTF-8\") ws = wb.add_sheet(\"douban_dataTOP250\") col = (\"电影详情链接\", \"图片链接\", \"影片中文名\", \"影片外国名\", \"评分\", \"评价数\", \"概况\", \"相关信息\") for i in range(0,8): ws.write(0,i,col[i]) #列名 for i in range(0,250): print(\"第%d条\" %(i+1)) data = datalist[i] for j in range(0,8): ws.write(i+1,j,data[j]) #写入数据 wb.save(savepath) #保存 # 得到一个指定的URL的网页内容 def askurl(url): head = { \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36\" \" (KHTML, like Gecko) Chrome/97.0.4692.99 Safari/537.36\" } html = \"\" try: req = urllib.request.Request(url=url, headers=head) response = urllib.request.urlopen(req) html= response.read().decode(\"UTF-8\") # print(html) except Exception as e: print(e) return html if __name__ == \"__main__\": main() print(\"爬取完毕\")   爬虫所用到的库 bs4(beautifulsoup)\nurllib\nre正则表达式  re.L 表示特殊字符集 \\w, \\W, \\b, \\B, \\s, \\S 依赖于当前环境 re.M 多行模式 re.S 即为' . ‘并且包括换行符在内的任意字符（’ . ‘不包括换行符） re.U 表示特殊字符集 \\w, \\W, \\b, \\B, \\d, \\D, \\s, \\S 依赖于 Unicode 字符属性数据库 re.X 为了增加可读性，忽略空格和’ # ‘后面的注释   ==注意==:\n 除了txt纯文本文件使用r来读取，其他类型的文件都是二进制文件用rb读取 乱码问题：Python内存层面使用的是Unicode编码，而Unicode不能存储和传输的，必须把Unicode编码进行转码(写文件时要编码，读文件时要解码)，转换成UTF-8或者GBK 得到的b’字符串’是==字节==，需要转码 在已经爬取得到网页后进行数据解析时，如果测试正则表达式没有问题但仍无数据时，可以加上re.S之类的re.compile(pattern[, flags])的flag参数 当使用BeautifulSoup的find(参数)参数中出现Python关键字时可以在关键字后面加__(PS: class_ = \"值\")  1 2 3  #如下面两种写法一样 find(classs_=\"table\") find(attrs={\"class\":\"table\"})   BeautifulSoup中如果想拿到某个属性的值，可以使用get(“要获取的属性名”)方法  ",
  "wordCount" : "3637",
  "inLanguage": "en",
  "datePublished": "2022-06-26T17:13:41+08:00",
  "dateModified": "2022-06-26T17:13:41+08:00",
  "author":[{
    "@type": "Person",
    "name": "hanson"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://hanson00.github.io/posts/technology/python/%E6%9D%8E%E5%B7%8D%E7%88%AC%E8%99%AB/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Hanson's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://hanson00.github.io/posts/imgs/66.jpg"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://hanson00.github.io/" accesskey="h" title="Hanson&#39;s Blog (Alt + H)">Hanson&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://hanson00.github.io/search" title="🔍搜索 (Alt &#43; /)" accesskey=/>
                    <span>🔍搜索</span>
                </a>
            </li>
            <li>
                <a href="https://hanson00.github.io/" title="🏠主页">
                    <span>🏠主页</span>
                </a>
            </li>
            <li>
                <a href="https://hanson00.github.io/posts" title="📚文章">
                    <span>📚文章</span>
                </a>
            </li>
            <li>
                <a href="https://hanson00.github.io/archives/" title="⏱时间轴">
                    <span>⏱时间轴</span>
                </a>
            </li>
            <li>
                <a href="https://hanson00.github.io/tags" title="🔖标签">
                    <span>🔖标签</span>
                </a>
            </li>
            <li>
                <a href="https://hanson00.github.io/about" title="🙋🏻‍♂️关于">
                    <span>🙋🏻‍♂️关于</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://hanson00.github.io/">Home</a>&nbsp;»&nbsp;<a href="https://hanson00.github.io/posts/">Posts</a>&nbsp;»&nbsp;<a href="https://hanson00.github.io/posts/technology/">💻技术类文章</a>&nbsp;»&nbsp;<a href="https://hanson00.github.io/posts/technology/python/">Python文章</a></div>
    <h1 class="post-title">
      李巍爬虫
    </h1>
    <div class="post-description">
      B站李巍爬虫学习总结
    </div>
    <div class="post-meta">














8 min&nbsp;|&nbsp;3637 words&nbsp;|&nbsp;
作者:&nbsp;hanson&nbsp;|&nbsp;

</div>
  </header> <aside id="toc-container" class="toc-container wide">
        <div class="toc">
            <details  open>
                <summary accesskey="c" title="(Alt + C)">
                    <span class="details">Table of Contents</span>
                </summary>

                <div class="inner"><ul>
                        <li>
                            <a href="#%e7%88%ac%e8%99%ab%e5%9f%ba%e7%a1%80" aria-label="爬虫基础">爬虫基础</a><ul>
                                    
                        <li>
                            <a href="#http%e8%af%b7%e6%b1%82%e6%96%b9%e6%b3%95" aria-label="HTTP请求方法">HTTP请求方法</a><ul>
                                    
                        <li>
                            <a href="#%e8%af%b7%e6%b1%82%e5%a4%b4" aria-label="请求头">请求头</a></li>
                        <li>
                            <a href="#%e5%93%8d%e5%ba%94" aria-label="响应">响应</a><ul>
                                    
                        <li>
                            <a href="#%e5%93%8d%e5%ba%94%e5%a4%b4" aria-label="响应头">响应头</a></li></ul>
                        </li></ul>
                        </li>
                        <li>
                            <a href="#%e5%b0%8f%e7%9f%a5%e8%af%86" aria-label="小知识">小知识</a></li>
                        <li>
                            <a href="#%e7%88%ac%e8%99%ab%e5%88%86%e7%b1%bb" aria-label="爬虫分类">爬虫分类</a><ul>
                                    
                        <li>
                            <a href="#%e9%80%9a%e7%94%a8%e7%88%ac%e8%99%ab" aria-label="通用爬虫">通用爬虫</a></li>
                        <li>
                            <a href="#%e8%81%9a%e7%84%a6%e7%88%ac%e8%99%ab" aria-label="聚焦爬虫">聚焦爬虫</a></li></ul>
                        </li>
                        <li>
                            <a href="#%e7%88%ac%e8%99%ab%e5%ad%a6%e4%b9%a0" aria-label="爬虫学习">爬虫学习</a><ul>
                                    
                        <li>
                            <a href="#urllibrequesturlopen" aria-label="urllib.request.urlopen()">urllib.request.urlopen()</a></li>
                        <li>
                            <a href="#urllibrequestrequest" aria-label="urllib.request.Request()">urllib.request.Request()</a></li>
                        <li>
                            <a href="#%e7%ae%80%e5%8d%95%e7%9a%84%e7%88%ac%e5%8f%96%e7%bd%91%e9%a1%b5" aria-label="简单的爬取网页">简单的爬取网页</a></li>
                        <li>
                            <a href="#beautifulsoup%e5%ba%93%e7%9a%84%e5%9f%ba%e6%9c%ac%e4%bd%bf%e7%94%a8%e7%88%ac%e8%99%ab%e7%9a%84%e8%a7%a3%e6%9e%90" aria-label="BeautifulSoup库的基本使用(爬虫的解析)">BeautifulSoup库的基本使用(爬虫的解析)</a><ul>
                                    
                        <li>
                            <a href="#beautifulsoup20%e6%96%87%e6%a1%a3%e6%90%9c%e7%b4%a2" aria-label="BeautifulSoup2.0文档搜索">BeautifulSoup2.0文档搜索</a></li></ul>
                        </li></ul>
                        </li>
                        <li>
                            <a href="#liwei%e7%88%ac%e8%99%ab%e5%ad%a6%e4%b9%a0%e7%9a%84%e6%9c%80%e7%bb%88" aria-label="liwei爬虫学习的最终">liwei爬虫学习的最终</a></li>
                        <li>
                            <a href="#%e7%88%ac%e8%99%ab%e6%89%80%e7%94%a8%e5%88%b0%e7%9a%84%e5%ba%93" aria-label="爬虫所用到的库">爬虫所用到的库</a></li>
                        <li>
                            <a href="#re%e6%ad%a3%e5%88%99%e8%a1%a8%e8%be%be%e5%bc%8f" aria-label="re正则表达式">re正则表达式</a>
                        </li>
                    </ul>
                    </li>
                    </ul>
                </div>
            </details>
        </div>
    </aside>
    <script>
        let activeElement;
        let elements;
        window.addEventListener('DOMContentLoaded', function (event) {
            checkTocPosition();

            elements = document.querySelectorAll('h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]');
            
            activeElement = elements[0];
            const id = encodeURI(activeElement.getAttribute('id')).toLowerCase();
            document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
        }, false);

        window.addEventListener('resize', function (event) {
            checkTocPosition();
        }, false);

        window.addEventListener('scroll', () => {
            
            activeElement = Array.from(elements).find((element) => {
                if ((getOffsetTop(element) - window.pageYOffset) > 0 &&
                    (getOffsetTop(element) - window.pageYOffset) < window.innerHeight / 2) {
                    return element;
                }
            }) || activeElement

            elements.forEach(element => {
                const id = encodeURI(element.getAttribute('id')).toLowerCase();
                if (element === activeElement) {
                    document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
                } else {
                    document.querySelector(`.inner ul li a[href="#${id}"]`).classList.remove('active');
                }
            })
        }, false);

        const main = parseInt(getComputedStyle(document.body).getPropertyValue('--article-width'), 10);
        const toc = parseInt(getComputedStyle(document.body).getPropertyValue('--toc-width'), 10);
        const gap = parseInt(getComputedStyle(document.body).getPropertyValue('--gap'), 10);

        function checkTocPosition() {
            const width = document.body.scrollWidth;

            if (width - main - (toc * 2) - (gap * 4) > 0) {
                document.getElementById("toc-container").classList.add("wide");
            } else {
                document.getElementById("toc-container").classList.remove("wide");
            }
        }

        function getOffsetTop(element) {
            if (!element.getClientRects().length) {
                return 0;
            }
            let rect = element.getBoundingClientRect();
            let win = element.ownerDocument.defaultView;
            return rect.top + win.pageYOffset;
        }
    </script>
  <div class="post-content"><h1 id="爬虫基础">爬虫基础<a hidden class="anchor" aria-hidden="true" href="#爬虫基础">#</a></h1>
<p>爬虫基本流程</p>
<p><code>1.初始化URL，并将URL放入待爬取的队列</code>
<code>2.将URl通过DNS解析IP，将对应IP的站点下载到HTML页面，并保存到本地，爬取完的URL放到已爬取队列</code>
<code>3.分析网页内容，找出网页里面关心的URL链接和内容，继续执行第二步</code></p>
<ol>
<li>获取网页</li>
<li>提取信息</li>
<li>保存数据</li>
<li>自动化程序</li>
</ol>
<p>爬虫如果需要模拟则把该网站下面的所有请求信息封装(例如UA)然后发送</p>
<h2 id="http请求方法">HTTP请求方法<a hidden class="anchor" aria-hidden="true" href="#http请求方法">#</a></h2>
<p>请求，是由客户端向服务器发出一般分为4部分内容：请求方法（request method）、请求的网址（request url）、请求头（request Headers）、请求体（request Body）</p>
<table>
<thead>
<tr>
<th>1</th>
<th>GET</th>
<th>请求指定的页面信息，并返回实体主体。</th>
</tr>
</thead>
<tbody>
<tr>
<td>2</td>
<td>HEAD</td>
<td>类似于 GET 请求，只不过返回的响应中没有具体的内容，用于获取报头</td>
</tr>
<tr>
<td>3</td>
<td>POST</td>
<td>向指定资源提交数据进行处理请求（例如提交表单或者上传文件）。数据被包含在请求体中。POST 请求可能会导致新的资源的建立和/或已有资源的修改。</td>
</tr>
<tr>
<td>4</td>
<td>PUT</td>
<td>从客户端向服务器传送的数据取代指定的文档的内容。</td>
</tr>
<tr>
<td>5</td>
<td>DELETE</td>
<td>请求服务器删除指定的页面。</td>
</tr>
<tr>
<td>6</td>
<td>CONNECT</td>
<td>HTTP/1.1 协议中预留给能够将连接改为管道方式的代理服务器。</td>
</tr>
<tr>
<td>7</td>
<td>OPTIONS</td>
<td>允许客户端查看服务器的性能。</td>
</tr>
<tr>
<td>8</td>
<td>TRACE</td>
<td>回显服务器收到的请求，主要用于测试或诊断。</td>
</tr>
<tr>
<td>9</td>
<td>PATCH</td>
<td>是对 PUT 方法的补充，用来对已知资源进行局部更新 。</td>
</tr>
</tbody>
</table>
<h3 id="请求头">请求头<a hidden class="anchor" aria-hidden="true" href="#请求头">#</a></h3>
<p>请求头，用来说明服务器要使用的附加信息，比较重要的信息有，<strong>cookie、Refer、User-Agent</strong></p>
<h3 id="响应">响应<a hidden class="anchor" aria-hidden="true" href="#响应">#</a></h3>
<p>响应，由服务器端返回给客户端，分为响应状态码（Response Status Code）、响应头（Response headers）、响应体（Response Body）</p>
<h4 id="响应头">响应头<a hidden class="anchor" aria-hidden="true" href="#响应头">#</a></h4>
<p>包含了服务器对请求的应答信息</p>
<hr>
<h2 id="小知识">小知识<a hidden class="anchor" aria-hidden="true" href="#小知识">#</a></h2>
<ul>
<li>Host:域名。表示请求的服务器网址</li>
</ul>
<hr>
<h2 id="爬虫分类">爬虫分类<a hidden class="anchor" aria-hidden="true" href="#爬虫分类">#</a></h2>
<h3 id="通用爬虫">通用爬虫<a hidden class="anchor" aria-hidden="true" href="#通用爬虫">#</a></h3>
<h3 id="聚焦爬虫">聚焦爬虫<a hidden class="anchor" aria-hidden="true" href="#聚焦爬虫">#</a></h3>
<hr>
<h2 id="爬虫学习">爬虫学习<a hidden class="anchor" aria-hidden="true" href="#爬虫学习">#</a></h2>
<p><code>urllib.request.urlopen(url, data=None, [timeout, ]*, cafile=None, capath=None, cadefault=False, context=None)</code>打开一个网页并把获取该URL的网页对象
<em>data</em> 必须是一个对象，用于给出要发送到服务器的附加数据，若不需要发送数据则为 <code>None</code>，data支持的对象类型包括字节串、类文件对象和可遍历的类字节串对象</p>
<h3 id="urllibrequesturlopen">urllib.request.urlopen()<a hidden class="anchor" aria-hidden="true" href="#urllibrequesturlopen">#</a></h3>
<blockquote>
<p>一个简单的get请求爬取</p>
</blockquote>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4">
<table style="border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#fff;font-weight:bold">import</span> urllib.request
<span style="color:#fff;font-weight:bold">import</span> urllib.parse     <span style="color:#007f7f">#解析器</span>
<span style="color:#fff;font-weight:bold">import</span> urllib.error

<span style="color:#007f7f">#Get请求</span>
response = urllib.request.urlopen(<span style="color:#0ff;font-weight:bold">&#34;http://www.baidu.com&#34;</span>)
<span style="color:#fff;font-weight:bold">print</span>(response.read().decode(<span style="color:#0ff;font-weight:bold">&#34;UTF-8&#34;</span>))		<span style="color:#007f7f"># response是&lt;http.client.HTTPResponse object at 0x000002DC28A404C0&gt;</span>

url = <span style="color:#0ff;font-weight:bold">&#34;http://httpbin.org/get&#34;</span>
response2 = urllib.request.urlopen(url=url)
<span style="color:#fff;font-weight:bold">print</span>(response2.read().decode(<span style="color:#0ff;font-weight:bold">&#34;UTF-8&#34;</span>))
</code></pre></td></tr></table>
</div>
</div><blockquote>
<p>一个简单的post请求(post请求需要提交个表单信息)，需要提供一个封装的数据</p>
</blockquote>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4">
<table style="border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">1
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">2
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">3
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">4
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">5
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#007f7f">#post请求  需要封装数据  http://httpbin.org/post</span>
url = <span style="color:#0ff;font-weight:bold">&#34;http://httpbin.org/post&#34;</span>
data = <span style="color:#fff;font-weight:bold">bytes</span>(urllib.parse.urlencode({<span style="color:#0ff;font-weight:bold">&#34;hello&#34;</span>:<span style="color:#0ff;font-weight:bold">&#34;world&#34;</span>}), encoding = <span style="color:#0ff;font-weight:bold">&#34;utf-8&#34;</span>)		<span style="color:#007f7f">#把数据变成二进制格式</span>
response = urllib.request.urlopen(url=url, data=data)
<span style="color:#fff;font-weight:bold">print</span>(response.read().decode(<span style="color:#0ff;font-weight:bold">&#34;utf-8&#34;</span>))
</code></pre></td></tr></table>
</div>
</div><h3 id="urllibrequestrequest">urllib.request.Request()<a hidden class="anchor" aria-hidden="true" href="#urllibrequestrequest">#</a></h3>
<p><code>urllib.request.Request(url, data=None, headers={}, origin_req_host=None, unverifiable=False, method=None)</code>
上面的urlopen过于简单直接把赋值的url直接打开，包含不了太多伪装信息，所以使用==urllib.request.Request()==</p>
<p>headers：告诉要访问的服务器，我们是什么类型的机器（浏览器），本质上是告诉浏览器我们可以接受什么水平的文件内容</p>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4">
<table style="border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">14
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#fff;font-weight:bold">import</span> urllib.request
<span style="color:#fff;font-weight:bold">import</span> urllib.parse     <span style="color:#007f7f">#解析器</span>
<span style="color:#fff;font-weight:bold">import</span> urllib.error
<span style="color:#007f7f"># http://httpbin.org/post    https://www.douban.com</span>
url = <span style="color:#0ff;font-weight:bold">&#34;http://httpbin.org/post&#34;</span>
headers = {<span style="color:#0ff;font-weight:bold">&#34;User-Agent&#34;</span>: <span style="color:#0ff;font-weight:bold">&#34;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36&#34;</span>
                         <span style="color:#0ff;font-weight:bold">&#34; (KHTML, like Gecko) Chrome/97.0.4692.99 Safari/537.36&#34;</span>}
data = <span style="color:#fff;font-weight:bold">bytes</span>(urllib.parse.urlencode({<span style="color:#0ff;font-weight:bold">&#34;name&#34;</span>:<span style="color:#0ff;font-weight:bold">&#34;hanson&#34;</span>}),encoding = <span style="color:#0ff;font-weight:bold">&#34;UTF-8&#34;</span>)

<span style="color:#007f7f">#封装了一个请求对象</span>
req = urllib.request.Request(url=url, data=data, headers=headers)   

response = urllib.request.urlopen(req)	<span style="color:#007f7f">#响应对象</span>
<span style="color:#fff;font-weight:bold">print</span>(response.read().decode(<span style="color:#0ff;font-weight:bold">&#34;UTF-8&#34;</span>))
</code></pre></td></tr></table>
</div>
</div><h3 id="简单的爬取网页">简单的爬取网页<a hidden class="anchor" aria-hidden="true" href="#简单的爬取网页">#</a></h3>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4">
<table style="border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">14
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">15
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">16
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">17
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">18
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">19
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">20
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">21
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">22
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">23
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">24
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">25
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">26
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">27
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">28
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">29
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">30
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">31
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">32
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">33
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">34
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">35
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">36
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">37
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">38
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">39
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">40
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">41
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">42
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">43
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">44
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">45
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">46
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">47
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#fff;font-weight:bold">import</span> urllib.request
<span style="color:#fff;font-weight:bold">import</span> urllib.error

<span style="color:#fff;font-weight:bold">def</span> main():
    <span style="color:#007f7f">#基础的URL</span>
    <span style="color:#007f7f"># 1.爬取网页</span>
    baseurl = <span style="color:#0ff;font-weight:bold">&#34;https://movie.douban.com/top250?start=&#34;</span>
    savepath = <span style="color:#0ff;font-weight:bold">r</span><span style="color:#0ff;font-weight:bold">&#34;D:\project\python pycharm\datasave\douban_data.xlsx&#34;</span>
    <span style="color:#007f7f"># datalist = getData(baseurl)</span>
    getData(baseurl)
    <span style="color:#007f7f">#2.解析数据</span>


    <span style="color:#007f7f">#3.保存数据</span>
    <span style="color:#007f7f"># saveData(savepath)</span>

<span style="color:#fff;font-weight:bold">def</span> getData(baseurl):
    datalist = []
    <span style="color:#fff;font-weight:bold">for</span> i in <span style="color:#fff;font-weight:bold">range</span>(<span style="color:#ff0;font-weight:bold">0</span>, <span style="color:#ff0;font-weight:bold">10</span>):
        url = baseurl + <span style="color:#fff;font-weight:bold">str</span>(i*<span style="color:#ff0;font-weight:bold">25</span>)
        html = askurl(url)

    <span style="color:#fff;font-weight:bold">return</span> datalist

    <span style="color:#007f7f"># 3.保存数据,在本列子中暂时不用</span>
<span style="color:#fff;font-weight:bold">def</span> saveData(savepath):
    <span style="color:#fff;font-weight:bold">pass</span>

<span style="color:#007f7f"># 得到一个指定的URL的网页内容</span>
<span style="color:#fff;font-weight:bold">def</span> askurl(url):
    head = {
        <span style="color:#0ff;font-weight:bold">&#34;User-Agent&#34;</span>: <span style="color:#0ff;font-weight:bold">&#34;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36&#34;</span>
                      <span style="color:#0ff;font-weight:bold">&#34; (KHTML, like Gecko) Chrome/97.0.4692.99 Safari/537.36&#34;</span>
    }
    html = <span style="color:#0ff;font-weight:bold">&#34;&#34;</span>
    <span style="color:#fff;font-weight:bold">try</span>:
        req = urllib.request.Request(url=url, headers=head)
        response = urllib.request.urlopen(req)
        html= response.read().decode(<span style="color:#0ff;font-weight:bold">&#34;UTF-8&#34;</span>)
        <span style="color:#fff;font-weight:bold">print</span>(html)
    <span style="color:#fff;font-weight:bold">except</span> Exception <span style="color:#fff;font-weight:bold">as</span> e:
        <span style="color:#fff;font-weight:bold">print</span>(e)
    <span style="color:#fff;font-weight:bold">return</span> html


<span style="color:#fff;font-weight:bold">if</span> __name__ == <span style="color:#0ff;font-weight:bold">&#34;__main__&#34;</span>:
    main()
</code></pre></td></tr></table>
</div>
</div><h3 id="beautifulsoup库的基本使用爬虫的解析">BeautifulSoup库的基本使用(爬虫的解析)<a hidden class="anchor" aria-hidden="true" href="#beautifulsoup库的基本使用爬虫的解析">#</a></h3>
<p>BeautifulSoup4将HTML文档转换成树形结构，每个节点都是Python对象，归类成四种：</p>
<ol>
<li>Tag	可以获取标签及其标签内容</li>
<li>NavigableString</li>
<li>BeautifulSoup</li>
<li>comment</li>
</ol>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4">
<table style="border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">14
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">15
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">16
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">17
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">18
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">19
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">20
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#fff;font-weight:bold">import</span> bs4
<span style="color:#fff;font-weight:bold">with</span> <span style="color:#fff;font-weight:bold">open</span>(<span style="color:#0ff;font-weight:bold">&#34;../baidu.html&#34;</span>, <span style="color:#0ff;font-weight:bold">&#34;rb&#34;</span>) <span style="color:#fff;font-weight:bold">as</span> file:
    htmlread = file.read()
    bs = bs4.BeautifulSoup(htmlread, <span style="color:#0ff;font-weight:bold">&#34;html.parser&#34;</span>)

    <span style="color:#007f7f"># Tag 获取标签及内容</span>
    <span style="color:#fff;font-weight:bold">print</span>(bs.title)     <span style="color:#007f7f">#output: &lt;title&gt;百度一下，你就知道 &lt;/title&gt;</span>
    <span style="color:#fff;font-weight:bold">print</span>(bs.a)         <span style="color:#007f7f">#output: &lt;a class=&#34;mnav&#34; href=&#34;http://news.baidu.com&#34; name=&#34;tj_trnews&#34;&gt;&lt;!--新闻--&gt;&lt;/a&gt;</span>
    <span style="color:#007f7f"># 获取标签里面的内容</span>
    <span style="color:#fff;font-weight:bold">print</span>(bs.title.string)      <span style="color:#007f7f">#output: 百度一下，你就知道</span>
    <span style="color:#fff;font-weight:bold">print</span>(bs.a.string)          <span style="color:#007f7f">#output: 新闻</span>

    <span style="color:#007f7f"># NavigableString 获取标签里的所有属性，并返回一个字典</span>
    <span style="color:#fff;font-weight:bold">print</span>(bs.a.attrs)   <span style="color:#007f7f">#attrs是attribute属性的缩写</span>

    <span style="color:#007f7f"># print(bs)    打印整个html文件</span>

    <span style="color:#007f7f"># 文件的遍历 contents</span>
    <span style="color:#fff;font-weight:bold">print</span>(<span style="color:#0ff;font-weight:bold">&#34;-----文档的遍历-----&#34;</span>)
    <span style="color:#fff;font-weight:bold">print</span>(bs.head.contents)     <span style="color:#007f7f">#返回一个列表</span>
</code></pre></td></tr></table>
</div>
</div><h4 id="beautifulsoup20文档搜索">BeautifulSoup2.0文档搜索<a hidden class="anchor" aria-hidden="true" href="#beautifulsoup20文档搜索">#</a></h4>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4">
<table style="border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">14
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">15
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">16
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">17
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">18
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">19
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">20
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">21
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">22
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">23
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">24
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">25
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">26
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">27
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">28
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">29
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">30
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">31
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">32
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">33
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">34
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">35
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">36
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">37
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">38
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">39
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">40
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">41
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">42
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">43
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">44
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">45
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#fff;font-weight:bold">import</span> re
<span style="color:#fff;font-weight:bold">import</span> bs4
<span style="color:#fff;font-weight:bold">with</span> <span style="color:#fff;font-weight:bold">open</span>(<span style="color:#0ff;font-weight:bold">&#34;../baidu.html&#34;</span>, <span style="color:#0ff;font-weight:bold">&#34;rb&#34;</span>) <span style="color:#fff;font-weight:bold">as</span> file:
    htmlread = file.read()
    bs = bs4.BeautifulSoup(htmlread, <span style="color:#0ff;font-weight:bold">&#34;html.parser&#34;</span>)

    <span style="color:#007f7f">#文档搜索</span>
    <span style="color:#007f7f"># 1. find_all()方法:字符串过滤会查找与字符串完全匹配的内容</span>
    <span style="color:#fff;font-weight:bold">list</span> = bs.find_all(<span style="color:#0ff;font-weight:bold">&#34;a&#34;</span>)
    <span style="color:#007f7f"># list = bs.find_all(&#34;a&#34;, limit = 3)   limit限制多少</span>
    <span style="color:#fff;font-weight:bold">print</span>(<span style="color:#fff;font-weight:bold">list</span>)

    <span style="color:#007f7f">#正则表达式搜索</span>
    <span style="color:#fff;font-weight:bold">print</span>(<span style="color:#0ff;font-weight:bold">&#34;---正则表达式搜索---&#34;</span>)
    re_list = bs.find_all(re.compile(<span style="color:#0ff;font-weight:bold">&#34;a&#34;</span>))
    <span style="color:#fff;font-weight:bold">print</span>(re_list)
    <span style="color:#fff;font-weight:bold">print</span>(<span style="color:#fff;font-weight:bold">len</span>(re_list))

    <span style="color:#007f7f">#传入一个函数作为参数进行搜索,按照函数进行搜索</span>
    <span style="color:#fff;font-weight:bold">print</span>(<span style="color:#0ff;font-weight:bold">&#34;---函数搜索---&#34;</span>)
    <span style="color:#fff;font-weight:bold">def</span> name_is_exists(tag):
        <span style="color:#fff;font-weight:bold">return</span> tag.has_attr(<span style="color:#0ff;font-weight:bold">&#34;name&#34;</span>)
    funcres = bs.find_all(name_is_exists)
    <span style="color:#fff;font-weight:bold">print</span>(funcres)

    <span style="color:#007f7f">#kwargs关键字搜索</span>
    <span style="color:#fff;font-weight:bold">print</span>(<span style="color:#0ff;font-weight:bold">&#34;----kwargs关键字搜索----&#34;</span>)
    kwlist = bs.find_all(<span style="color:#fff;font-weight:bold">id</span> = <span style="color:#0ff;font-weight:bold">&#34;head&#34;</span>)
    kwlist2 = bs.find_all(href = <span style="color:#0ff;font-weight:bold">&#34;https://www.hao123.com&#34;</span>)
    kwlist3 = bs.find_all(class_ = <span style="color:#fff;font-weight:bold">True</span>)    <span style="color:#007f7f">#这里class加下划线是因为class是Python的关键字</span>
    <span style="color:#fff;font-weight:bold">print</span>(kwlist3)

    <span style="color:#007f7f">#text文本参数,查找标签里的字符串</span>
    <span style="color:#fff;font-weight:bold">print</span>(<span style="color:#0ff;font-weight:bold">&#34;----text文本参数-----&#34;</span>)
    ts_list = bs.find_all(text=<span style="color:#0ff;font-weight:bold">&#34;hao123&#34;</span>)
    ts_list2 = bs.find_all(text=[<span style="color:#0ff;font-weight:bold">&#34;hao123&#34;</span>, <span style="color:#0ff;font-weight:bold">&#34;地图&#34;</span>])
    <span style="color:#fff;font-weight:bold">print</span>(ts_list2)

    <span style="color:#007f7f">#css选择器,和css选择器的语法一样</span>
    <span style="color:#fff;font-weight:bold">print</span>(<span style="color:#0ff;font-weight:bold">&#34;------css选择器-------&#34;</span>)
    css_list = bs.select(<span style="color:#0ff;font-weight:bold">&#34;title&#34;</span>)
    css_list2 = bs.select(<span style="color:#0ff;font-weight:bold">&#34;.mnav&#34;</span>)
    css_list3 = bs.select(<span style="color:#0ff;font-weight:bold">&#34;#u1&#34;</span>)
    css_list4 = bs.select(<span style="color:#0ff;font-weight:bold">&#34;a[class = &#39;bri&#39;]&#34;</span>)
    <span style="color:#fff;font-weight:bold">print</span>(css_list3)
</code></pre></td></tr></table>
</div>
</div><h2 id="liwei爬虫学习的最终">liwei爬虫学习的最终<a hidden class="anchor" aria-hidden="true" href="#liwei爬虫学习的最终">#</a></h2>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4">
<table style="border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">  1
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">  2
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">  3
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">  4
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">  5
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">  6
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">  7
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">  8
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">  9
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 10
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 11
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 12
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 13
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 14
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 15
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 16
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 17
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 18
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 19
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 20
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 21
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 22
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 23
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 24
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 25
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 26
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 27
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 28
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 29
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 30
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 31
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 32
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 33
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 34
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 35
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 36
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 37
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 38
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 39
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 40
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 41
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 42
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 43
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 44
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 45
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 46
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 47
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 48
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 49
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 50
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 51
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 52
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 53
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 54
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 55
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 56
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 57
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 58
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 59
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 60
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 61
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 62
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 63
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 64
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 65
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 66
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 67
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 68
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 69
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 70
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 71
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 72
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 73
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 74
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 75
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 76
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 77
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 78
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 79
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 80
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 81
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 82
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 83
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 84
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 85
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 86
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 87
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 88
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 89
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 90
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 91
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 92
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 93
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 94
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 95
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 96
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 97
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 98
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 99
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">100
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">101
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">102
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">103
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">104
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">105
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">106
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">107
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">108
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#007f7f"># coding:utf-8</span>
<span style="color:#007f7f"># @Time : 2022/5/7 9:57</span>
<span style="color:#007f7f"># @Author : 软件1194温铭军</span>
<span style="color:#007f7f"># @file : ts.py</span>
<span style="color:#007f7f"># $software : PyCharm</span>
<span style="color:#fff;font-weight:bold">import</span> bs4
<span style="color:#fff;font-weight:bold">import</span> re
<span style="color:#fff;font-weight:bold">import</span> xlwt
<span style="color:#fff;font-weight:bold">import</span> urllib.request
<span style="color:#fff;font-weight:bold">import</span> urllib.error

<span style="color:#fff;font-weight:bold">def</span> main():
    baseurl = <span style="color:#0ff;font-weight:bold">&#34;https://movie.douban.com/top250?start=&#34;</span>  <span style="color:#007f7f">#待爬取的URL</span>
    savepath = <span style="color:#0ff;font-weight:bold">r</span><span style="color:#0ff;font-weight:bold">&#34;D:\project\python pycharm\datasave\douban_data.xls&#34;</span>    <span style="color:#007f7f">#保存位置</span>
    datalist = getData(baseurl)     <span style="color:#007f7f">#爬取到的数据列表</span>
    <span style="color:#007f7f"># getData(baseurl)</span>
    <span style="color:#007f7f"># print(datalist)</span>
    <span style="color:#007f7f">#3.保存数据</span>
    saveData(datalist,savepath)

<span style="color:#007f7f"># 提取影片的提取规则</span>
recom_link = re.compile(<span style="color:#0ff;font-weight:bold">r</span><span style="color:#0ff;font-weight:bold">&#39;&lt;a href=&#34;(.*?)&#34;&gt;&#39;</span>)
recom_img = re.compile(<span style="color:#0ff;font-weight:bold">r</span><span style="color:#0ff;font-weight:bold">&#39;&lt;img alt=&#34;.*? src=&#34;(.*?)&#34;.*?/&gt;&#39;</span>, re.S)     <span style="color:#007f7f">#re.S让换行符也包含在内</span>
recom_title = re.compile(<span style="color:#0ff;font-weight:bold">r</span><span style="color:#0ff;font-weight:bold">&#39;&lt;span class=&#34;title&#34;&gt;(.*?)&lt;/span&gt;&#39;</span>)
recom_rating = re.compile(<span style="color:#0ff;font-weight:bold">r</span><span style="color:#0ff;font-weight:bold">&#39;&lt;span class=&#34;rating_num&#34; property=&#34;v:average&#34;&gt;(.*?)&lt;/span&gt;&#39;</span>)
recom_judge = re.compile(<span style="color:#0ff;font-weight:bold">r</span><span style="color:#0ff;font-weight:bold">&#39;&lt;span&gt;(\d*)人评价&lt;/span&gt;&#39;</span>)
recom_inq = re.compile(<span style="color:#0ff;font-weight:bold">r</span><span style="color:#0ff;font-weight:bold">&#39;&lt;span class=&#34;inq&#34;&gt;(.*?)&lt;/span&gt;&#39;</span>)
recom_db = re.compile(<span style="color:#0ff;font-weight:bold">r</span><span style="color:#0ff;font-weight:bold">&#39;&lt;p class=&#34;&#34;&gt;(.*?)&lt;/p&gt;&#39;</span>,re.S)

<span style="color:#fff;font-weight:bold">def</span> getData(baseurl):
    datalist = []
    <span style="color:#007f7f">#生成要爬取的网址</span>
    <span style="color:#fff;font-weight:bold">for</span> i in <span style="color:#fff;font-weight:bold">range</span>(<span style="color:#ff0;font-weight:bold">0</span>, <span style="color:#ff0;font-weight:bold">10</span>):
        url = baseurl + <span style="color:#fff;font-weight:bold">str</span>(i*<span style="color:#ff0;font-weight:bold">25</span>)
        html = askurl(url)

        <span style="color:#007f7f">#进行数据解析</span>
        soup = bs4.BeautifulSoup(html, <span style="color:#0ff;font-weight:bold">&#34;html.parser&#34;</span>)
        <span style="color:#fff;font-weight:bold">for</span> item in soup.find_all(<span style="color:#0ff;font-weight:bold">&#34;div&#34;</span>, class_ = <span style="color:#0ff;font-weight:bold">&#34;item&#34;</span>):	<span style="color:#007f7f">#在&lt;class &#39;bs4.BeautifulSoup&#39;&gt;中查找是div并且class=&#34;item&#34;的内容</span>
            <span style="color:#007f7f"># print(item)</span>
            data = []   <span style="color:#007f7f">#保存每一部电影的信息</span>
            item = <span style="color:#fff;font-weight:bold">str</span>(item)
            link = re.findall(recom_link, item)[<span style="color:#ff0;font-weight:bold">0</span>]
            data.append(link)   <span style="color:#007f7f">#添加链接</span>
            img = re.findall(recom_img, item)[<span style="color:#ff0;font-weight:bold">0</span>]
            data.append(img)
            title = re.findall(recom_title, item)
            <span style="color:#fff;font-weight:bold">if</span> (<span style="color:#fff;font-weight:bold">len</span>(title) ==<span style="color:#ff0;font-weight:bold">2</span>):
                ctitle = title[<span style="color:#ff0;font-weight:bold">0</span>]
                data.append(ctitle)
                otitle = title[<span style="color:#ff0;font-weight:bold">1</span>].replace(<span style="color:#0ff;font-weight:bold">&#34;/&#34;</span>,<span style="color:#0ff;font-weight:bold">&#34;&#34;</span>)   <span style="color:#007f7f">#去掉无关符号</span>
                data.append(otitle)
            <span style="color:#fff;font-weight:bold">else</span>:
                data.append(title[<span style="color:#ff0;font-weight:bold">0</span>])
                data.append(<span style="color:#0ff;font-weight:bold">&#34; &#34;</span>)    <span style="color:#007f7f">#留空</span>
            rating = re.findall(recom_rating, item)[<span style="color:#ff0;font-weight:bold">0</span>]
            data.append(rating)
            judge = re.findall(recom_judge, item)[<span style="color:#ff0;font-weight:bold">0</span>]
            data.append(judge)
            inq = re.findall(recom_inq, item)
            <span style="color:#fff;font-weight:bold">if</span> <span style="color:#fff;font-weight:bold">len</span>(inq) !=<span style="color:#ff0;font-weight:bold">0</span>:
                inq = inq[<span style="color:#ff0;font-weight:bold">0</span>].replace(<span style="color:#0ff;font-weight:bold">&#34;。&#34;</span>, <span style="color:#0ff;font-weight:bold">&#34; &#34;</span>)
                data.append(inq)
            <span style="color:#fff;font-weight:bold">else</span>:
                data.append(<span style="color:#0ff;font-weight:bold">&#34; &#34;</span>)
            db = re.findall(recom_db, item)[<span style="color:#ff0;font-weight:bold">0</span>]
            db = re.sub(<span style="color:#0ff;font-weight:bold">&#39;&lt;br(\s+)?/&gt;(\s+)?&#39;</span>, <span style="color:#0ff;font-weight:bold">&#34;&#34;</span>, db)
            db = re.sub(<span style="color:#0ff;font-weight:bold">&#39;/&#39;</span>, <span style="color:#0ff;font-weight:bold">&#34; &#34;</span>, db)
            data.append(db.strip())
            datalist.append(data)
    <span style="color:#007f7f"># print(datalist)</span>
    <span style="color:#fff;font-weight:bold">return</span> datalist

    <span style="color:#007f7f"># 3.保存数据</span>
<span style="color:#fff;font-weight:bold">def</span> saveData(datalist,savepath):
    wb = xlwt.Workbook(encoding=<span style="color:#0ff;font-weight:bold">&#34;UTF-8&#34;</span>)
    ws = wb.add_sheet(<span style="color:#0ff;font-weight:bold">&#34;douban_dataTOP250&#34;</span>)
    col = (<span style="color:#0ff;font-weight:bold">&#34;电影详情链接&#34;</span>, <span style="color:#0ff;font-weight:bold">&#34;图片链接&#34;</span>, <span style="color:#0ff;font-weight:bold">&#34;影片中文名&#34;</span>, <span style="color:#0ff;font-weight:bold">&#34;影片外国名&#34;</span>, <span style="color:#0ff;font-weight:bold">&#34;评分&#34;</span>, <span style="color:#0ff;font-weight:bold">&#34;评价数&#34;</span>, <span style="color:#0ff;font-weight:bold">&#34;概况&#34;</span>, <span style="color:#0ff;font-weight:bold">&#34;相关信息&#34;</span>)
    <span style="color:#fff;font-weight:bold">for</span> i in <span style="color:#fff;font-weight:bold">range</span>(<span style="color:#ff0;font-weight:bold">0</span>,<span style="color:#ff0;font-weight:bold">8</span>):
        ws.write(<span style="color:#ff0;font-weight:bold">0</span>,i,col[i]) <span style="color:#007f7f">#列名</span>
    <span style="color:#fff;font-weight:bold">for</span> i in <span style="color:#fff;font-weight:bold">range</span>(<span style="color:#ff0;font-weight:bold">0</span>,<span style="color:#ff0;font-weight:bold">250</span>):
        <span style="color:#fff;font-weight:bold">print</span>(<span style="color:#0ff;font-weight:bold">&#34;第</span><span style="color:#0ff;font-weight:bold">%d</span><span style="color:#0ff;font-weight:bold">条&#34;</span> %(i+<span style="color:#ff0;font-weight:bold">1</span>))
        data = datalist[i]
        <span style="color:#fff;font-weight:bold">for</span> j in <span style="color:#fff;font-weight:bold">range</span>(<span style="color:#ff0;font-weight:bold">0</span>,<span style="color:#ff0;font-weight:bold">8</span>):
            ws.write(i+<span style="color:#ff0;font-weight:bold">1</span>,j,data[j])      <span style="color:#007f7f">#写入数据</span>

    wb.save(savepath)       <span style="color:#007f7f">#保存</span>

<span style="color:#007f7f"># 得到一个指定的URL的网页内容</span>
<span style="color:#fff;font-weight:bold">def</span> askurl(url):
    head = {
        <span style="color:#0ff;font-weight:bold">&#34;User-Agent&#34;</span>: <span style="color:#0ff;font-weight:bold">&#34;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36&#34;</span>
                      <span style="color:#0ff;font-weight:bold">&#34; (KHTML, like Gecko) Chrome/97.0.4692.99 Safari/537.36&#34;</span>
    }
    html = <span style="color:#0ff;font-weight:bold">&#34;&#34;</span>
    <span style="color:#fff;font-weight:bold">try</span>:
        req = urllib.request.Request(url=url, headers=head)
        response = urllib.request.urlopen(req)
        html= response.read().decode(<span style="color:#0ff;font-weight:bold">&#34;UTF-8&#34;</span>)
        <span style="color:#007f7f"># print(html)</span>
    <span style="color:#fff;font-weight:bold">except</span> Exception <span style="color:#fff;font-weight:bold">as</span> e:
        <span style="color:#fff;font-weight:bold">print</span>(e)
    <span style="color:#fff;font-weight:bold">return</span> html


<span style="color:#fff;font-weight:bold">if</span> __name__ == <span style="color:#0ff;font-weight:bold">&#34;__main__&#34;</span>:
    main()
    <span style="color:#fff;font-weight:bold">print</span>(<span style="color:#0ff;font-weight:bold">&#34;爬取完毕&#34;</span>)
</code></pre></td></tr></table>
</div>
</div><h2 id="爬虫所用到的库">爬虫所用到的库<a hidden class="anchor" aria-hidden="true" href="#爬虫所用到的库">#</a></h2>
<p>bs4(beautifulsoup)</p>
<p>urllib</p>
<h2 id="re正则表达式">re正则表达式<a hidden class="anchor" aria-hidden="true" href="#re正则表达式">#</a></h2>
<ul>
<li>re.L 表示特殊字符集 \w, \W, \b, \B, \s, \S 依赖于当前环境</li>
<li>re.M 多行模式</li>
<li>re.S 即为' . &lsquo;并且<strong>包括换行符在内的任意字符</strong>（&rsquo; . &lsquo;不包括换行符）</li>
<li>re.U 表示特殊字符集 \w, \W, \b, \B, \d, \D, \s, \S 依赖于 Unicode 字符属性数据库</li>
<li>re.X 为了增加可读性，忽略空格和&rsquo; # &lsquo;后面的注释</li>
</ul>
<hr>
<p>==注意==:</p>
<ol>
<li>除了txt纯文本文件使用r来读取，其他类型的文件都是二进制文件用rb读取</li>
<li>乱码问题：Python内存层面使用的是Unicode编码，而Unicode不能存储和传输的，必须把Unicode编码进行转码(写文件时要编码，读文件时要解码)，转换成UTF-8或者GBK</li>
<li>得到的b&rsquo;字符串&rsquo;是==字节==，需要转码</li>
<li>在已经爬取得到网页后进行数据解析时，如果测试正则表达式没有问题但仍无数据时，可以加上re.S之类的<code>re.compile(pattern[, flags])</code>的flag参数</li>
<li>当使用BeautifulSoup的find(参数)参数中出现Python关键字时可以在关键字后面加__(PS: <code>class_ = &quot;值&quot;</code>)</li>
</ol>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4">
<table style="border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">1
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">2
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">3
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py"><span style="color:#007f7f">#如下面两种写法一样</span>
find(classs_=<span style="color:#0ff;font-weight:bold">&#34;table&#34;</span>)
find(attrs={<span style="color:#0ff;font-weight:bold">&#34;class&#34;</span>:<span style="color:#0ff;font-weight:bold">&#34;table&#34;</span>})
</code></pre></td></tr></table>
</div>
</div><ol start="6">
<li>BeautifulSoup中如果想拿到某个属性的值，可以使用get(&ldquo;要获取的属性名&rdquo;)方法</li>
</ol>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://hanson00.github.io/tags/%E7%88%AC%E8%99%AB/">爬虫</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="https://hanson00.github.io/posts/technology/python/%E8%B7%AF%E9%A3%9E%E7%88%AC%E8%99%AB%E8%BF%9B%E9%98%B6%E7%88%AC%E8%99%AB/">
    <span class="title">« Prev</span>
    <br>
    <span>路飞爬虫进阶爬虫</span>
  </a>
  <a class="next" href="https://hanson00.github.io/posts/technology/golang/01gin/">
    <span class="title">Next »</span>
    <br>
    <span>01gin</span>
  </a>
</nav>

  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2022 <a href="https://hanson00.github.io/">Hanson&#39;s Blog</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
